{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de7886bf-2d75-4094-aea7-604b255523ce",
   "metadata": {},
   "source": [
    "# Tiny Transformer LM (GPT-style)\n",
    "\n",
    "This notebook implements a tint decoder-only Transformer language model with:\n",
    "\n",
    "1. Configuration & Reproducible Seeding\n",
    "2. Data Utilities (character-level corpus, vocabulary, batching)\n",
    "3. Core modules:\n",
    "    - scaled dot product attention\n",
    "    - multi-head self attention\n",
    "    - feedforward block\n",
    "    - transformer block\n",
    "4. \"TinyTransformerLM\" model class\n",
    "5. Training loop with cross-entropy loss\n",
    "6. Logging, simple run-tracking and checkpoints\n",
    "7. Sampling / text generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da5a690-b8c2-4c61-9534-5310d83324fd",
   "metadata": {},
   "source": [
    "# The Infrastructure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1bd463-35b4-4306-a375-0bbfa5adccf5",
   "metadata": {},
   "source": [
    "<b><u>Architecture</b></u>\n",
    "\n",
    "This project is built on a modular, reproducible infrastructure designed to support GPU-accelerated machine learning while keeping costs low and the development experience seamless. The computational backend runs on a DigitalOcean GPU Droplet, which provides dedicated NVIDIA GPU hardware suitable for training and experimentation. All code execution happens inside a Docker container on the droplet. The containerised environment guarantees reproducibility and isolation: dependencies, Python versions, CUDA-enabled libraries, and runtime behaviour remain consistent across sessions, regardless of host configuration. The project repository on the droplet is mounted into the container at /workspace, allowing source code to be edited externally while still running inside the GPU-enabled runtime.\n",
    "\n",
    "Development itself is performed locally using PyCharm Professional, which connects to the GPU droplet using an SSH remote interpreter. This allows Python scripts to run directly inside the container on the GPU, while maintaining the full convenience and responsiveness of a local IDE—file browsing, autocomplete, linting, debugging, and version control integration all operate as if the environment were local. Jupyter notebooks are served from within the running container and accessed securely over an SSH port-forwarding tunnel, enabling interactive GPU-backed experimentation through the user’s browser on their local machine.\n",
    "\n",
    "<b><u>Automated Environment Scaffolding</b></u>\n",
    "\n",
    "To make the infrastructure fully reproducible—and to minimise cloud compute costs—the project uses a Bash-based automation workflow. A local scaffolding script generates the directory structure and starter files (src/, notebooks/, tests/, scripts/, Dockerfile, requirements.txt, etc.), ensuring a clean, predictable layout across all machines. On the cloud side, the aie_full_setup.sh script serves as a complete end-to-end bootstrapper for fresh GPU droplets. When executed on a new droplet, the script:\n",
    "\n",
    "1. Installs system dependencies such as Docker, Git, Python, and virtual-environment tools.\n",
    "\n",
    "2. Pulls the latest version of the project from GitHub.\n",
    "\n",
    "3. Builds the project’s Docker image.\n",
    "\n",
    "4. Creates and runs a GPU-enabled container with the project directory mounted into it.\n",
    "\n",
    "5. Creates and activates a Python virtual environment inside the container.\n",
    "\n",
    "6. Installs all Python dependencies and optionally CUDA-enabled PyTorch.\n",
    "\n",
    "7. Drops the user into an interactive shell inside the container, ready for training.\n",
    "\n",
    "This automation provides a powerful workflow: GPU droplets can be created on demand, fully configured in minutes, used to run model training or experimentation, and then safely destroyed afterwards. Since all source code and notebooks are stored in GitHub, the entire environment can be recreated at any time without keeping expensive GPU instances running. The result is an affordable, scalable, and entirely reproducible development pipeline for AI engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b799564-76ef-486b-bb3a-854d12fe242b",
   "metadata": {},
   "source": [
    "## The Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b3c203-4496-407e-aa1b-c1c76799f9f6",
   "metadata": {},
   "source": [
    "1. 'TinyTransformerLM' embeds tokens amd positions -> produces initial representations.\n",
    "2. It sends then throgh a stack of *TransformerBlocks*\n",
    "    Each block consists of:\n",
    "        - *MultiHeadSelfAttention*: tokens communicate with past tokens and gather context\n",
    "        - *FeedForward*: transforms each tokens representation non-linearly\n",
    "        - Residual + LayerNorm help stability and flow\n",
    "3. The final hidden stattes go through a linear projection -> logits\n",
    "4. Logits give a probability distribution over the *next token* at each position.\n",
    "5. Training teaches the model to reduce negative log-liklihood (cross entropy).\n",
    "6. At generation time, the model samples tokens autoregressively using teh same logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97c0dc4-b609-460b-8d14-4f93867f008a",
   "metadata": {},
   "source": [
    "# The Project - Building a Large Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8cee8b-faf4-40f3-b81d-353f3013ddeb",
   "metadata": {},
   "source": [
    "This large-language-model (LLM) is a GPT style implementation and is flexible in how it represents text, supporting both character-level ('char') and word-level ('word') operation. At the character level, the model treats each individual character as a token, giving it a very small vocabulary and allowing it to learn fine-grained patterns such as spelling, punctuation, and stylistic rhythms. This makes the model simple and extremely general, though sequences become longer and learning long-range structure is harder. At the word level, the model tokenises whole words, dramatically reducing sequence length and enabling it to capture semantic and syntactic relationships more directly. This comes at the cost of a larger vocabulary and reduced ability to generalise to unseen words. Supporting both modes allows you to switch seamlessly between high-resolution modelling of text structure and higher-level linguistic abstraction, depending on the task.\n",
    "\n",
    "<b>Selection of 'char' or 'word' is performed in the cell 'Config and Runn Tracking'</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47350b29-0d84-4e56-b2f6-e67390114b8d",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f775f8ba-3bd6-4cf7-bfbe-795b85cf2a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from dataclasses import dataclass, asdict\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ce670c-326b-4308-9606-8ebcb2f14b0a",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b41c72d-6409-402f-a9c0-f2274cfd02be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_top_k(logits: Tensor, top_k: int | None) -> Tensor:\n",
    "    \"\"\"\n",
    "    Keep only top_k logits per row, set the rest to -inf.\n",
    "    logits: (B, V)\n",
    "    \"\"\"\n",
    "    if top_k is None or top_k <= 0:\n",
    "        return logits\n",
    "\n",
    "    # Get top_k values; kth value is at index top_k-1\n",
    "    v, _ = torch.topk(logits, k=top_k, dim=-1)\n",
    "    kth_values = v[..., -1, None]  # (B, 1)\n",
    "\n",
    "    # Mask out everything below the kth largest logit\n",
    "    return torch.where(\n",
    "        logits < kth_values,\n",
    "        torch.full_like(logits, -float(\"inf\")),\n",
    "        logits,\n",
    "    )\n",
    "\n",
    "\n",
    "def apply_top_p(logits: Tensor, top_p: float | None) -> Tensor:\n",
    "    \"\"\"\n",
    "    Nucleus (top-p) filtering.\n",
    "    Keep the smallest number of tokens whose cumulative probability >= top_p.\n",
    "    logits: (B, V)\n",
    "    \"\"\"\n",
    "    if top_p is None or top_p <= 0.0 or top_p >= 1.0:\n",
    "        return logits\n",
    "\n",
    "    # Sort logits descending\n",
    "    sorted_logits, sorted_indices = torch.sort(logits, dim=-1, descending=True)\n",
    "\n",
    "    # Convert to sorted probabilities\n",
    "    sorted_probs = F.softmax(sorted_logits, dim=-1)\n",
    "\n",
    "    # Cumulative probabilities\n",
    "    cumulative_probs = torch.cumsum(sorted_probs, dim=-1)\n",
    "\n",
    "    # Mask tokens where cumulative prob > top_p\n",
    "    sorted_mask = cumulative_probs > top_p\n",
    "    # Always keep at least the first token\n",
    "    sorted_mask[..., 0] = False\n",
    "\n",
    "    # Set masked logits to -inf\n",
    "    sorted_logits[sorted_mask] = -float(\"inf\")\n",
    "\n",
    "    # Unsort back to original token order\n",
    "    logits_filtered = torch.full_like(logits, -float(\"inf\"))\n",
    "    logits_filtered.scatter_(-1, sorted_indices, sorted_logits)\n",
    "    return logits_filtered\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4de220-c66a-4460-8579-8f82caed9e9b",
   "metadata": {},
   "source": [
    "# Device and Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ba40be4-4af7-424f-869e-5e35f9387a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device:  cuda\n"
     ]
    }
   ],
   "source": [
    "# device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"using device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce84bbe6-d988-4df1-ae66-710731236c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int, deterministic: bool = True) -> None:\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    if deterministic:\n",
    "        torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8e64dc-a5e0-43e0-80b3-b1011f9c9ef4",
   "metadata": {},
   "source": [
    "# Config and Run Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "697b6aff-b122-47ea-8e32-6e8f3b8ec99d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config(block_size=16, batch_size=32, train_val_split=0.9, level='word', d_model=64, num_heads=2, num_layers=1, d_ff=128, dropout=0.2, learning_rate=0.0003, max_steps=2000, eval_interval=200, seed=123)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Please select character ('char') or word ('word') level implementation\n",
    "in the line:\n",
    "    level: str = \"word\"            # \"char\" or \"word\"\n",
    "\"\"\"\n",
    "@dataclass\n",
    "class Config:\n",
    "    # Data\n",
    "    block_size: int = 16    \n",
    "    batch_size: int = 32\n",
    "    train_val_split: float = 0.9\n",
    "    level: str = \"word\"            # \"char\" or \"word\"\n",
    "\n",
    "    # Model\n",
    "    d_model: int = 64       # was 128\n",
    "    num_heads: int = 2      # was 4\n",
    "    num_layers: int = 1     # was 2\n",
    "    d_ff: int = 128         # was 256\n",
    "    dropout: float = 0.2    # was 0.1\n",
    "\n",
    "    # Optimization\n",
    "    learning_rate: float = 3e-4\n",
    "    max_steps: int = 2000\n",
    "    eval_interval: int = 200\n",
    "\n",
    "    # Reproducibility\n",
    "    seed: int = 123\n",
    "\n",
    "@dataclass\n",
    "class RunRecord:\n",
    "    config: dict\n",
    "    created_at: str\n",
    "    run_dir: str\n",
    "    final_step: int = 0\n",
    "    final_train_loss: float = float(\"nan\")\n",
    "    final_val_loss: float = float(\"nan\")\n",
    "\n",
    "cfg = Config()\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f5532432-b967-47df-9a70-740d6b6e8ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD level implementation selected\n"
     ]
    }
   ],
   "source": [
    "print(f\"{(cfg.level).upper()} level implementation selected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785fd074-6674-495e-b29d-92101f586fb3",
   "metadata": {},
   "source": [
    "# Run Directory and JSON helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "835f56b9-f1a7-4eb0-a5d5-db5ba7597d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_RUN_DIR = Path(\"runs\")\n",
    "\n",
    "def make_run_dir(base_dir: Path, cfg: Config) -> Path:\n",
    "    stamp = datetime.now().strftime(\"%Y%m%dT%H%M%S\")\n",
    "    name = f\"{stamp}_seed{cfg.seed}_tiny_transformer\"\n",
    "    run_dir = base_dir / name\n",
    "    (run_dir / \"checkpoints\").mkdir(parents=True, exist_ok=True)\n",
    "    return run_dir\n",
    "\n",
    "def save_json(path: Path, data: dict) -> None:\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915462c7-f08b-4812-b7d3-6e78de756168",
   "metadata": {},
   "source": [
    "# Set seed and create run directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9ccc93bd-536e-4179-b198-92348b7d3e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run directory: runs/20251209T032001_seed123_tiny_transformer\n"
     ]
    }
   ],
   "source": [
    "set_seed(cfg.seed, deterministic=False)\n",
    "run_dir = make_run_dir(BASE_RUN_DIR, cfg)\n",
    "print(\"Run directory:\", run_dir)\n",
    "\n",
    "# Initial run record\n",
    "record = RunRecord(\n",
    "    config=asdict(cfg),\n",
    "    created_at=datetime.now().isoformat(timespec=\"seconds\"),\n",
    "    run_dir=str(run_dir),\n",
    ")\n",
    "\n",
    "save_json(run_dir / \"config.json\", asdict(cfg))\n",
    "save_json(run_dir / \"run_record.json\", asdict(record))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8625265a-cac3-43c8-8cef-e9676225462f",
   "metadata": {},
   "source": [
    "# Add text of Gekko speech from the 1987 movie \"Wall Street\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ff1f8c2b-fb86-41d4-b571-de8ae924fca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length (characters): 2439\n",
      "[Gekko:] Well, I appreciate the opportunity you're giving me, Mr. Cromwell, as the single largest \n",
      "shareholder in Teldar Paper, to speak. Well, ladies and gentlemen, we're not here to indulge in fanta\n"
     ]
    }
   ],
   "source": [
    "raw_text = \"\"\"[Gekko:] Well, I appreciate the opportunity you're giving me, Mr. Cromwell, as the single largest \n",
    "shareholder in Teldar Paper, to speak. Well, ladies and gentlemen, we're not here to indulge in fantasy, but \n",
    "in political and economic reality. America, America has become a second-rate power. Its trade deficit and \n",
    "its fiscal deficit are at nightmare proportions. Now, in the days of the free market, when our country was a \n",
    "top industrial power, there was accountability to the stockholder. The Carnegies, the Mellons, the men that \n",
    "built this great industrial empire, made sure of it because it was their money at stake. Today, management \n",
    "has no stake in the company! All together, these men sitting up here own less than 3 percent of the company. \n",
    "And where does Mr. Cromwell put his million-dollar salary? Not in Teldar stock; he owns less than 1 percent. \n",
    "You own the company. That's right -- you, the stockholder. And you are all being royally screwed over by these, \n",
    "these bureaucrats, with their steak lunches, their hunting and fishing trips, their corporate jets and golden \n",
    "parachutes. [Cromwell:] This is an outrage! You're out of line, Gekko! [Gekko:] Teldar Paper, Mr. Cromwell, Teldar \n",
    "Paper has 33 different vice presidents, each earning over 200 thousand dollars a year. Now, I have spent the last \n",
    "two months analyzing what all these guys do, and I still can't figure it out. One thing I do know is that our paper \n",
    "company lost 110 million dollars last year, and I'll bet that half of that was spent in all the paperwork going back \n",
    "and forth between all these vice presidents. The new law of evolution in corporate America seems to be survival of \n",
    "the unfittest. Well, in my book you either do it right or you get eliminated. In the last seven deals that I've been \n",
    "involved with, there were 2.5 million stockholders who have made a pretax profit of 12 billion dollars. Thank you. I am \n",
    "not a destroyer of companies. I am a liberator of them!The point is, ladies and gentleman, that greed -- for lack of a better \n",
    "word -- Greed is good. Greed is right. Greed works. Greed clarifies, cuts through, and captures the essence of the evolutionary \n",
    "spirit. Greed, in all of its forms -- greed for life, for money, for love, knowledge -- has marked the upward surge of mankind. \n",
    "And greed -- you mark my words -- will not only save Teldar Paper, but that other malfunctioning corporation called the USA. \n",
    "Thank you very much.\"\"\"\n",
    "\n",
    "print(\"Corpus length (characters):\", len(raw_text))\n",
    "print(raw_text[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402a9c80-22dc-4fec-bc80-5d617033655e",
   "metadata": {},
   "source": [
    "# Vocabulary and Enconde / Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7fa535cb-ddf3-4e7c-9a1c-87f720860b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization level: word\n",
      "Vocab size: 251\n",
      "test:    Greed is good.\n",
      "encoded: [22, 126, 111, 4]\n",
      "decoded: Greed is good.\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokenization level:\", cfg.level)\n",
    "\n",
    "if cfg.level == \"char\":\n",
    "    # ----- Character-level: each character is a token -----\n",
    "    tokens = list(raw_text)               # e.g. [\"T\", \"o\", \" \", \"b\", \"e\", ...]\n",
    "    vocab = sorted(set(tokens))\n",
    "    \n",
    "    stoi = {ch: i for i, ch in enumerate(vocab)}\n",
    "    itos = {i: ch for ch, i in stoi.items()}\n",
    "    \n",
    "    def encode(s: str):\n",
    "        \"\"\"Encode string to list of integer IDs (char-level).\"\"\"\n",
    "        return [stoi[ch] for ch in s]\n",
    "    \n",
    "    def decode(ids):\n",
    "        \"\"\"Decode list of integer IDs back to string (char-level).\"\"\"\n",
    "        return \"\".join(itos[i] for i in ids)\n",
    "\n",
    "elif cfg.level == \"word\":\n",
    "    # ----- Word-level: lightweight word + punctuation tokenizer -----\n",
    "    def tokenize(s: str):\n",
    "        \"\"\"\n",
    "        Split text into words and punctuation.\n",
    "        Example:\n",
    "          \"Greed is good. Greed is right\" ->\n",
    "          [\"Greed\", \"is\", \"good\", \".\", \"Greed\", \"is\", \"right\"]\n",
    "        \"\"\"\n",
    "        # \\w+  = one or more word chars (letters/digits/_)\n",
    "        # \\S   = any non-whitespace character (captures punctuation)\n",
    "        return re.findall(r\"\\w+|\\S\", s)\n",
    "    \n",
    "    def detokenize(tokens):\n",
    "        \"\"\"\n",
    "        Join tokens back into a string, fixing spaces before punctuation.\n",
    "        \"\"\"\n",
    "        text = \" \".join(tokens)\n",
    "        # Remove space before common punctuation: \"word , next\" -> \"word, next\"\n",
    "        text = re.sub(r\"\\s+([.,!?;:])\", r\"\\1\", text)\n",
    "        # Optional: \"(\" + \" word\" -> \"(word\"\n",
    "        text = re.sub(r\"([\\(\\[\\{])\\s+\", r\"\\1\", text)\n",
    "        return text\n",
    "    \n",
    "    tokens = tokenize(raw_text)\n",
    "    vocab = sorted(set(tokens))\n",
    "    \n",
    "    stoi = {tok: i for i, tok in enumerate(vocab)}\n",
    "    itos = {i: tok for tok, i in stoi.items()}\n",
    "    \n",
    "    def encode(s: str):\n",
    "        \"\"\"Encode string to list of integer IDs (word-level).\"\"\"\n",
    "        return [stoi[t] for t in tokenize(s)]\n",
    "    \n",
    "    def decode(ids):\n",
    "        \"\"\"Decode list of integer IDs back to string (word-level).\"\"\"\n",
    "        toks = [itos[i] for i in ids]\n",
    "        return detokenize(toks)\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Unknown cfg.level: {cfg.level!r}\")\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "print(\"Vocab size:\", vocab_size)\n",
    "\n",
    "# Quick sanity test\n",
    "test = \"Greed is good.\"\n",
    "encoded = encode(test)\n",
    "decoded = decode(encoded)\n",
    "print(\"test:   \", test)\n",
    "print(\"encoded:\", encoded)\n",
    "print(\"decoded:\", decoded)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac746d3-4dda-41f6-8f9b-6b6f1c22e4be",
   "metadata": {},
   "source": [
    "# Quick test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "578bd3ff-b0ae-4313-9a85-f66d1b15a367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: Greed is good\n",
      "encoded: [22, 126, 111]\n",
      "decoded: Greed is good\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "251"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"Greed is good\"\n",
    "encoded = encode(test)\n",
    "decoded = decode(encoded)\n",
    "print(\"test:\", test)\n",
    "print(\"encoded:\", encoded)\n",
    "print(\"decoded:\", decoded)\n",
    "\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cef778-bde0-4ac3-b0f3-f2daaba870b6",
   "metadata": {},
   "source": [
    "# Create tensor and Train/Val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "772022a9-2abc-4434-9d56-fd82a3f0ab1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape (number of tokens): torch.Size([532])\n",
      "Train tokens: 478 Val tokens: 54\n"
     ]
    }
   ],
   "source": [
    "# Turn full corpus into a long 1D tensor of token IDs\n",
    "data = torch.tensor(encode(raw_text), dtype=torch.long)\n",
    "print(\"Data shape (number of tokens):\", data.shape)\n",
    "\n",
    "# Train/val split\n",
    "n = int(len(data) * cfg.train_val_split)\n",
    "train_data = data[:n]\n",
    "val_data   = data[n:]\n",
    "print(\"Train tokens:\", len(train_data), \"Val tokens:\", len(val_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd24288-69ad-4b62-ad02-3a13895bc7c1",
   "metadata": {},
   "source": [
    "# Batch sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3266ba08-18be-4683-8cbf-203dfdd8ab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split: str):\n",
    "    source = train_data if split == \"train\" else val_data\n",
    "    B, T = cfg.batch_size, cfg.block_size\n",
    "\n",
    "    if len(source) <= T + 1:\n",
    "        raise ValueError(\n",
    "            f\"Not enough tokens in {split} split \"\n",
    "            f\"for block_size={T}. len(source)={len(source)}.\"\n",
    "        )\n",
    "\n",
    "    max_start = len(source) - T - 1\n",
    "    ix = torch.randint(0, max_start, (B,))\n",
    "    x = torch.stack([source[i : i + T] for i in ix])\n",
    "    y = torch.stack([source[i + 1 : i + 1 + T] for i in ix])\n",
    "    return x.to(device), y.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fe2258-e3e1-48d3-86ff-86c81535b99a",
   "metadata": {},
   "source": [
    "# Scaled dot product attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "049e04f9-19b8-43eb-b1f5-2379fc688516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q: Tensor, k: Tensor, v: Tensor, mask: Tensor | None = None) -> Tensor:\n",
    "    \"\"\"\n",
    "    q, k, v: [B, H, T, Hd]\n",
    "    mask:   [T, T] or None (1 = keep, 0 = mask out)\n",
    "    Returns: [B, H, T, Hd]\n",
    "    \"\"\"\n",
    "    d_k = q.size(-1)\n",
    "    scores = q @ k.transpose(-2, -1) / math.sqrt(d_k)  # [B, H, T, T]\n",
    "\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, float(\"-inf\"))\n",
    "        \n",
    "    attn = torch.softmax(scores, dim=-1) # should be [B, H, T, T]\n",
    "    out = attn @ v                       # should be [B, H, T, Hd]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c53bbf-1329-40a4-92f5-c5154ada3e1c",
   "metadata": {},
   "source": [
    "# Multi Head Self Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8300aa-3687-4d1f-9672-415cac803f54",
   "metadata": {},
   "source": [
    "This class asks \"what tokens should I pay attention to\". Multi head self attention enables each token in the sequence to look at other tokens, decide which ines arerelevant, and gather information from them.\n",
    "\n",
    "for language modelling this is how the model:\n",
    "\n",
    "    - understands dependencies\n",
    "    - tracks long range relationships\n",
    "    - carries semantic information forward\n",
    "    - builds contextual meaning\n",
    "\n",
    "<b><u>What happens inside this class:</b></u>\n",
    "\n",
    "At a high level for each position t:\n",
    "    1. the model creates a *query, key, value* for every token.\n",
    "    2. it computes *similarity scores* between the query at position t and the keys at all earlier positions.\n",
    "    3. Using softmax it converts these scores into *attention weights*.\n",
    "    4. It uses these weights to take a *weighted sum of the value vectors*.\n",
    "    5. This becomes the representation of the token in the next layer\n",
    "\n",
    "<b><u>Why \"multi-head\":</b></u>\n",
    "Each head can learn a different pattern eg it is possible that:\n",
    "    * One head tracks syntax\n",
    "    * One tracks names\n",
    "    * One tracks verb tense\n",
    "    * One tracks quotation boundaries, and so on...\n",
    "\n",
    "<b><u>Why Causal Masking:</b></u>\n",
    "It is important that token t does not see the future (i.e. t+1, t+2,...) otherwise themodel would cheat during training. Masking ensure that the model is truly able to learn * Given the past, predict the next token*\n",
    "\n",
    "### MultiHeadSelfAttention teaches the model how tokens relate to each other and forms the backbone of reasoning and contextual understanding in LLM's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "edca7a19-3c59-49aa-9716-f5c61ff8143f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, d_model: int, num_heads: int, block_size: int):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "\n",
    "        self.W_q = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.W_k = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.W_v = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.W_o = nn.Linear(d_model, d_model, bias=False)\n",
    "\n",
    "        mask = torch.tril(torch.ones(block_size, block_size))\n",
    "        self.register_buffer(\"causal_mask\", mask)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        B, T, D = x.shape\n",
    "        H, Hd = self.num_heads, self.head_dim\n",
    "\n",
    "        q = self.W_q(x)  # [B, T, D]\n",
    "        k = self.W_k(x)\n",
    "        v = self.W_v(x)\n",
    "\n",
    "        # [B, T, D] -> [B,, H, T, Hd]\n",
    "        q = q.view(B, T, H, Hd).transpose(1, 2)\n",
    "        k = k.view(B, T, H, Hd).transpose(1, 2)\n",
    "        v = v.view(B, T, H, Hd).transpose(1, 2)\n",
    "\n",
    "        out = scaled_dot_product_attention(q, k, v, mask=self.causal_mask[:T, :T])\n",
    "\n",
    "        # [B, H, T, Hd] -> [B, T, D]\n",
    "        out = out.transpose(1, 2).contiguous().view(B, T, D)\n",
    "        out = self.W_o(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe40a85b-3f67-4f4b-a7a7-70d50fdb43ff",
   "metadata": {},
   "source": [
    "# FeedForward "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc20ccf8-ee97-4170-8c28-9c6d67188b16",
   "metadata": {},
   "source": [
    "### Purpose in an LLM - \"Transform the information that I've gathered\"\n",
    "\n",
    "After self attention mixes information across positions, the feedforward network applies a *nonlinear transformation* to each token independently. This step allows the model to:\n",
    "\n",
    "    - extract higher level features\n",
    "    - create richer internal representations\n",
    "    - perform local computations over each tokesn embedding\n",
    "    - increase the models expressive capacity\n",
    "\n",
    "<b><u>What is does</b></u>\n",
    "Inside the TransformerBlock, FeedForward component is implemented using PyTorch's nn.Sequential, which applies a small neural network of the form:\n",
    "\n",
    "$\\text{FFN}(x) = W_2\\,\\mathrm{ReLU}(W_1 x)$\n",
    "\n",
    "This: \n",
    "\n",
    "    - Increases dimensionality (*expansion* via W1)\n",
    "    - Applies a nonlinerity (ReLU)\n",
    "    - Project back to the original dimension (*compression* via W2)\n",
    "\n",
    "This pattern (expand -> nonlinear -> compress) lets the transformer model complex functions that cannot be captured by attention alone.\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1afee0cd-d9ef-41d7-ad60-45e04fdf9b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model: int, d_ff: int):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_ff, d_model),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f5e96a-b318-4381-b563-83b66aaac07f",
   "metadata": {},
   "source": [
    "# TransformerBlock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6663bc5-893d-4c00-8006-ff7e602a4296",
   "metadata": {},
   "source": [
    "A *TransformerBlock* combines several key components that work together to progressivley refine token representations as information flows through the model. Each block begins with <i>layer normalisation</i>, followed by <i>multi-head self attention</i>, which allows eaxh token to gather contextual information from earlier tokens in the sequence. A <i>residual connection</i> then preserves the original representation while adding the newly computed attention output, stabilising learning and improving gradient flow. This block applies a second layer normalisation before passing each token through a <i>feedforward network</i>, which performs a nonlinear transformation that enriches and expands the representation locally. Another residdual connection integrates this transformation with the tokens prior state. Stacking multiple blocks in depth enables the model to build a representational hierarchy: lower layers capture syrface-level patterns such as character sequences, middle layers learn grammatical structure and short range semantics, and upper layers develop broader more abstract meaning. Residual pathways throughout the block - mathematically in the form $x_{\\text{next}} = x + f(x)$ ensure stable optimisation by allowing gradients to propogate effectively, preventing representational collaose and making deeper transformers trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "41912a26-b78a-4a17-a57a-e2d71c87f21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model: int,\n",
    "        num_heads: int,\n",
    "        d_ff: int,\n",
    "        block_size: int,\n",
    "        dropout: float,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(d_model)\n",
    "        self.ln2 = nn.LayerNorm(d_model)\n",
    "        self.attn = MultiHeadSelfAttention(d_model, num_heads, block_size)\n",
    "        self.ff = FeedForward(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        # GPT-style pre-norm + residual + dropout\n",
    "        x = x + self.dropout(self.attn(self.ln1(x)))\n",
    "        x = x + self.dropout(self.ff(self.ln2(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a92431-5d46-4d92-bf04-d5ebd99b20df",
   "metadata": {},
   "source": [
    "# Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "649e262b-2e8e-4324-ab4a-1477fe38fddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len: int):\n",
    "        super().__init__()\n",
    "        # pe: (T_max, d_model)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)  # (T_max, 1)\n",
    "\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2, dtype=torch.float32)\n",
    "            * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "        # Even indices: sin\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        # Odd indices: cos\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)  # (1, T_max, d_model)\n",
    "        # register as buffer so it moves with the module to CUDA, but has no gradients\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        x: (B, T, d_model)\n",
    "        returns: x + positional encodings for first T positions\n",
    "        \"\"\"\n",
    "        T = x.size(1)\n",
    "        # self.pe[:, :T, :] -> (1, T, d_model), broadcast over batch\n",
    "        return x + self.pe[:, :T, :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54da2af6-f625-4601-91c5-af8f56016463",
   "metadata": {},
   "source": [
    "# TinyTransformerLM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6258872f-07af-4377-a7ae-e8fe1ae0c4fe",
   "metadata": {},
   "source": [
    "The TinyTransformer \"Token -> Meaning -> Prediction\" wraps the entire transformer architecture and produces logits at each position, which we use for next-token prediction.\n",
    "\n",
    "<b><u>Workflow inside the forward</u></b>\n",
    "\n",
    "1. Token embeddings - convert token id's into vectors\n",
    "2. Position embeddings - add information about position in the sequence\n",
    "3. Pass through L Transformer blocks - each block refines and contextualises the embeddings\n",
    "4. FInal `LayerNorm` and `Linear` Layer - convert the final hidden states into Logits over the vocabulary\n",
    "\n",
    "<b><u>Why Logits</u></b>\n",
    "\n",
    "Becuase `CrossEntropyLoss` takes Logits and computes - logP0(Xt | X < t). This creates a next token prediction becuase given input tokens X0, X1, X2,...,X(t - 1) the model predicts a districution over x(t) for every position t in the sequence simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "741b9f07-dae1-410e-8e15-7bb77f1784ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 65472\n"
     ]
    }
   ],
   "source": [
    "class TinyTransformerLM(nn.Module):\n",
    "    def __init__(self, vocab_size: int, cfg: Config):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.token_emb = nn.Embedding(vocab_size, cfg.d_model)\n",
    "\n",
    "        # Sinusoidal positional encodings\n",
    "        self.pos_encoding = PositionalEncoding(\n",
    "            d_model=cfg.d_model,\n",
    "            max_len=cfg.block_size,\n",
    "        )\n",
    "\n",
    "        # Dropout applied after adding positional encodings\n",
    "        self.drop = nn.Dropout(cfg.dropout)\n",
    "\n",
    "        self.blocks = nn.ModuleList([\n",
    "            TransformerBlock(\n",
    "                d_model=cfg.d_model,\n",
    "                num_heads=cfg.num_heads,\n",
    "                d_ff=cfg.d_ff,\n",
    "                block_size=cfg.block_size,\n",
    "                dropout=cfg.dropout,\n",
    "            )\n",
    "            for _ in range(cfg.num_layers)\n",
    "        ])\n",
    "\n",
    "        self.ln_f = nn.LayerNorm(cfg.d_model)\n",
    "        self.head = nn.Linear(cfg.d_model, vocab_size, bias=False)\n",
    "\n",
    "    def forward(self, idx: Tensor) -> Tensor:\n",
    "        B, T = idx.shape\n",
    "        assert T <= self.cfg.block_size, \"Sequence length > block_size\"\n",
    "\n",
    "        tok = self.token_emb(idx)          # [B, T, D]\n",
    "        x = self.pos_encoding(tok)         # add sinusoidal PE\n",
    "        x = self.drop(x)                   # embedding + position dropout\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.head(x)              # [B, T, V]\n",
    "        return logits\n",
    "\n",
    "\n",
    "model = TinyTransformerLM(vocab_size, cfg).to(device)\n",
    "print(\"Number of parameters:\", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acebcf2-ceac-442c-bbcd-f9fdc6771b5b",
   "metadata": {},
   "source": [
    "# Loss Estimation Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d3d3c1f5-711e-4678-8c7c-e6730a3b696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    model.eval()\n",
    "    out = {}\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        losses = []\n",
    "        for _ in range(10):  # a few mini-batches\n",
    "            xb, yb = get_batch(split)      # <<--- use get_batch, not get_batch_split\n",
    "            logits = model(xb)\n",
    "            B, T, V = logits.shape\n",
    "            loss = F.cross_entropy(\n",
    "                logits.view(B * T, V),\n",
    "                yb.view(B * T),\n",
    "            )\n",
    "            losses.append(loss.item())\n",
    "        out[split] = sum(losses) / len(losses)\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c03f51e-2882-42b2-bafe-603910550022",
   "metadata": {},
   "source": [
    "# Training Loop with logging & checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4056053e-41ee-4273-9ad5-1c8d2ea1dc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step     0: train loss 5.6153, val loss 5.6236\n",
      "  → New best val loss, checkpoint saved to runs/20251209T032001_seed123_tiny_transformer/checkpoints/best.pt\n",
      "step   200: train loss 3.4468, val loss 5.1323\n",
      "  → New best val loss, checkpoint saved to runs/20251209T032001_seed123_tiny_transformer/checkpoints/best.pt\n",
      "step   400: train loss 1.7758, val loss 5.3058\n",
      "step   600: train loss 1.0004, val loss 5.8663\n",
      "step   800: train loss 0.6664, val loss 6.2982\n",
      "step  1000: train loss 0.4694, val loss 6.7149\n",
      "step  1200: train loss 0.3453, val loss 7.1961\n",
      "step  1400: train loss 0.2379, val loss 7.4892\n",
      "step  1600: train loss 0.1941, val loss 7.7137\n",
      "step  1800: train loss 0.1555, val loss 7.9571\n",
      "Final checkpoint saved to: runs/20251209T032001_seed123_tiny_transformer/checkpoints/last.pt\n"
     ]
    }
   ],
   "source": [
    "train_steps = []\n",
    "train_losses_history = []\n",
    "val_losses_history = []\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=cfg.learning_rate)\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "for step in range(cfg.max_steps):\n",
    "    # ---- Periodic evaluation ----\n",
    "    if step % cfg.eval_interval == 0:\n",
    "        losses = estimate_loss()\n",
    "        train_loss, val_loss = losses[\"train\"], losses[\"val\"]\n",
    "        print(f\"step {step:5d}: train loss {train_loss:.4f}, val loss {val_loss:.4f}\")\n",
    "\n",
    "        # Record the losses\n",
    "        train_steps.append(step)\n",
    "        train_losses_history.append(train_loss)\n",
    "        val_losses_history.append(val_loss)\n",
    "\n",
    "        # Update run record\n",
    "        record.final_step = step\n",
    "        record.final_train_loss = float(train_loss)\n",
    "        record.final_val_loss = float(val_loss)\n",
    "        save_json(run_dir / \"run_record.json\", asdict(record))\n",
    "\n",
    "        # Save checkpoint if best so far\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            ckpt_path = run_dir / \"checkpoints\" / \"best.pt\"\n",
    "            torch.save(model.state_dict(), ckpt_path)\n",
    "            print(f\"  → New best val loss, checkpoint saved to {ckpt_path}\")\n",
    "\n",
    "    # Sample a training batch\n",
    "    xb, yb = get_batch(\"train\")\n",
    "\n",
    "    # Forward\n",
    "    logits = model(xb)                         # [B, T, V]\n",
    "    B, T, V = logits.shape\n",
    "    loss = F.cross_entropy(\n",
    "        logits.view(B * T, V),\n",
    "        yb.view(B * T),\n",
    "    )\n",
    "\n",
    "    # Backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # Optional gradient clipping\n",
    "    # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "\n",
    "# Final save of model\n",
    "final_ckpt = run_dir / \"checkpoints\" / \"last.pt\"\n",
    "torch.save(model.state_dict(), final_ckpt)\n",
    "print(\"Final checkpoint saved to:\", final_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "eeaf0733-b9f7-4a24-afef-08cdf9ebc4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(train_steps, train_losses_history, label=\"Train Loss\", marker='o')\n",
    "plt.plot(train_steps, val_losses_history, label=\"Validation Loss\", marker='o')\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "083b0c80-044f-4e4d-9b27-db577792b85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate(\n",
    "    model: TinyTransformerLM,\n",
    "    idx: Tensor,\n",
    "    max_new_tokens: int,\n",
    "    *,\n",
    "    temperature: float = 1.0,\n",
    "    greedy: bool = False,\n",
    "    top_k: int | None = None,\n",
    "    top_p: float | None = None,\n",
    ") -> Tensor:\n",
    "    \"\"\"\n",
    "    Backwards-compatible generate() function.\n",
    "\n",
    "    New features:\n",
    "        - greedy=True          → argmax sampling\n",
    "        - temperature=τ        → scale logits\n",
    "        - top_k=k              → keep only top-k tokens\n",
    "        - top_p=p              → nucleus sampling\n",
    "\n",
    "    If you call it like before:\n",
    "        generate(model, idx, max_new_tokens)\n",
    "    it behaves EXACTLY as the original version (multinomial sampling).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "\n",
    "        # Use only last block_size tokens as context\n",
    "        idx_cond = idx[:, -cfg.block_size:]\n",
    "\n",
    "        # Forward pass: (B, T, V)\n",
    "        logits = model(idx_cond)\n",
    "\n",
    "        # Take only the last timestep (B, V)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # ---- Temperature scaling ----\n",
    "        logits = logits / temperature\n",
    "\n",
    "        # ---- Greedy sampling ----\n",
    "        if greedy:\n",
    "            next_id = torch.argmax(logits, dim=-1, keepdim=True)  # (B, 1)\n",
    "        else:\n",
    "            # ---- Optional top-k ----\n",
    "            if top_k is not None and top_k > 0:\n",
    "                v, _ = torch.topk(logits, k=top_k, dim=-1)\n",
    "                kth = v[:, -1].unsqueeze(-1)\n",
    "                logits = torch.where(\n",
    "                    logits < kth,\n",
    "                    torch.full_like(logits, -float(\"inf\")),\n",
    "                    logits\n",
    "                )\n",
    "\n",
    "            # ---- Optional top-p (nucleus sampling) ----\n",
    "            if top_p is not None and 0 < top_p < 1.0:\n",
    "                sorted_logits, sorted_idx = torch.sort(logits, descending=True, dim=-1)\n",
    "                sorted_probs = torch.softmax(sorted_logits, dim=-1)\n",
    "                cumulative = torch.cumsum(sorted_probs, dim=-1)\n",
    "\n",
    "                # Mask tokens after nucleus boundary\n",
    "                mask = cumulative > top_p\n",
    "                mask[:, 0] = False  # always keep the highest token\n",
    "                sorted_logits[mask] = -float(\"inf\")\n",
    "\n",
    "                # Map back to original index order\n",
    "                logits = torch.full_like(logits, -float(\"inf\"))\n",
    "                logits.scatter_(1, sorted_idx, sorted_logits)\n",
    "\n",
    "            # ---- Sample from distribution ----\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            next_id = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
    "\n",
    "        # Append sampled token\n",
    "        idx = torch.cat([idx, next_id], dim=1)\n",
    "\n",
    "    return idx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445b24c5-1028-4936-a00d-2c9cd055b94d",
   "metadata": {},
   "source": [
    "# Sampling / Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "701ba381-8cab-4c77-b0ad-08ec6bca67eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy:\n",
      " Greed is good. Cromwell, the last the last the last the last - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "\n",
      "Temperature (τ=0.8):\n",
      " Greed is good. The put right. rate these Greed this, in going gentleman, ladies and gentleman re, in market. Greed there. Greed a destroyer guys vice the evolutionary back. Now, And in the. different gentlemen is I ' re am free 3,\n",
      "\n",
      "Top-k (k=20):\n",
      " Greed is good. Cromwell that half a - - - - - dollars. Well of a has. In a presidents,, as a - -. Thank dollars are Cromwell, and right power, and fishing and has you either half ' s Mr, and its Teldar\n",
      "\n",
      "Top-p (p=0.9):\n",
      " Greed is good top industrial and I and upward 5 was to ] industrial months, in, the company vice Now as ' re. am Mr. was this shareholder [where; right,. salary am The One dollars is and do seems indulge it point lunches in corporate\n",
      "\n",
      "Temp((τ=0.8) Top-p (p=0.9):\n",
      " Greed is good dollar and different no - power. Greed a rate its Mr. owns still there was Its no owns of the works and its. Now, we ladies a industrial money vice, ladies Mr. thing I - rate, you, the eliminated [word right\n"
     ]
    }
   ],
   "source": [
    "# Load best checkpoint (optional, but recommended)\n",
    "best_ckpt = run_dir / \"checkpoints\" / \"best.pt\"\n",
    "model.load_state_dict(torch.load(best_ckpt, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# Choose a prompt\n",
    "prompt = \"Greed is good\"\n",
    "start_ids = torch.tensor([encode(prompt)], dtype=torch.long, device=device)  # (1, T0)\n",
    "\n",
    "# 1) Greedy sampling\n",
    "out_greedy = generate(model, start_ids, 50, greedy=True)\n",
    "print(\"Greedy:\\n\", decode(out_greedy[0].tolist()))\n",
    "\n",
    "# 2) Temperature sampling\n",
    "out_temp = generate(model, start_ids, 50, temperature=0.7)\n",
    "print(\"\\nTemperature (τ=0.8):\\n\", decode(out_temp[0].tolist()))\n",
    "\n",
    "# 3) Top-k sampling\n",
    "out_topk = generate(model, start_ids, 50, top_k=20)\n",
    "print(\"\\nTop-k (k=20):\\n\", decode(out_topk[0].tolist()))\n",
    "\n",
    "# 4) Top-p sampling\n",
    "out_topp = generate(model, start_ids, 50, top_p=0.9)\n",
    "print(\"\\nTop-p (p=0.9):\\n\", decode(out_topp[0].tolist()))\n",
    "\n",
    "# 5) Temperature and Top-p sampling\n",
    "out_temp_topp = generate(model, start_ids, 50, temperature=0.8, top_p=0.9)\n",
    "print(\"\\nTemp((τ=0.8) Top-p (p=0.9):\\n\", decode(out_temp_topp[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d2ca9b9d-9f0c-4e0c-b59c-02ae9e11c4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accountability Mr. Greed a. And days Well industrial empire. stock! You fantasy Cromwell last this are forth. America that lack paperwork not greed parachutes, shareholder that greed days. Cromwell profit Greed accountability to the largest new save One Cromwell. Its Well fantasy country, these vice lunches America, there. t not Cromwell power: have it Well country forth these Mr company Its there t dollars. giving power still Mr of trips. surge. survival. made know of evolution for Thank reality to here in it percent! I am lack and save t the save - and I. In a proportions That dollars and. ll together. Greed company? screwed destroyer. proportions deals deficit [, and forth I top of companies Well, free this, the last dollar ll is of the paperwork called its what Gekko get. 5, of the steak single the a clarifies than, and Mellons their put. 200. each profit 200 there have and my year Now, been gentleman was of line own last are who analyzing Thank liberator other word\n"
     ]
    }
   ],
   "source": [
    "# Example: Start from \"word\"\n",
    "if cfg.level == 'word':\n",
    "    start_gekko_letter=\"accountability\"\n",
    "else:\n",
    "    start_gekko_letter=\"a\"\n",
    "generate_gekko_tokens=200\n",
    "start_ids = torch.tensor([[stoi[start_gekko_letter]]], dtype=torch.long, device=device)\n",
    "sample_ids = generate(model, start_ids, max_new_tokens=generate_gekko_tokens)\n",
    "print(decode(sample_ids[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b8ee72-dfcc-4f15-ba5e-fdf92f4dff74",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2315b9b-fff2-43f1-bc84-da9a2bf730c8",
   "metadata": {},
   "source": [
    "## Conclusion: What These Results Say About Overfitting, Data Scarcity, and Sampling\n",
    "\n",
    "These generation results are entirely consistent with what we saw in the training curves. The model drives the **training loss almost to zero**, while the **validation loss stays high and eventually rises**, even after adding `dropout = 0.2` in an attempt to improve generalisation.  \n",
    "The dropout helps a little at the margin, but the model still has far more capacity than the dataset can support, so it simply memorises the training text. In other words, the bottleneck is not regularisation—it is the lack of data.\n",
    "\n",
    "That understanding allows us to explain everything we see across the sampling methods.\n",
    "\n",
    "### • Greedy sampling\n",
    "Greedy decoding immediately collapses into loops like *“the last the last the last …”*.  \n",
    "This is exactly what happens when the next-token distribution is dominated by a few memorised transitions. Greedy decoding exposes that.\n",
    "\n",
    "### • Temperature sampling (τ = 0.8)\n",
    "Lowering the temperature adds noise, but it doesn’t magically create structure.  \n",
    "Because the underlying distribution is already extremely narrow, the model just mixes together half-remembered phrases and odd fragments. It can’t invent anything new — it can only return what it has memorised.\n",
    "\n",
    "### • Top-k sampling (k = 20)\n",
    "Restricting the distribution produces cleaner output, but the model still falls back to short, memorised fragments with only light variation.  \n",
    "Top-k slightly improves coherence, but it doesn’t fix the underlying problem: there is nothing meaningful to sample from.\n",
    "\n",
    "### • Top-p sampling (p = 0.9)\n",
    "Top-p gives the most variety. It forces the model to explore beyond the single most likely transitions, which leads to the pseudo-poetic mixtures like  \n",
    "*“jets. there cuts dollars... survival... evolution... percent!”*  \n",
    "This looks more interesting, but it is still just recombination of training material, not real generalisation.\n",
    "\n",
    "### • Temperature + Top-p\n",
    "The combined sampler gives the most structured output of the set. But even here the model keeps circling back to the same phrases — *“Greed … million year … pretax profit … paperwork …”* — because those are the fragments it has memorised.  \n",
    "The sampler can change how the model moves through its probability space, but it cannot fix a probability space that has been shaped entirely by overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "## Broader Takeaways\n",
    "\n",
    "These experiments illustrate the core challenge of language modelling in tiny-data regimes:\n",
    "\n",
    "- With too little data, the model learns **memorisation**, not **generalisation**.\n",
    "- With **word-level tokenisation**, overfitting shows up as repetition of full sentences or entire phrases.\n",
    "- With **character-level tokenisation**, the model memorises local patterns (spelling, punctuation) and generates more varied but still shallow text.\n",
    "- No sampling strategy can compensate for a model whose distributions are shaped almost entirely by memorised fragments.\n",
    "\n",
    "Modern LLMs avoid all of this by combining:\n",
    "\n",
    "- extremely large and diverse datasets,  \n",
    "- subword tokenisation to balance vocabulary size with expressiveness, and  \n",
    "- architectures whose capacity is aligned with data scale.\n",
    "\n",
    "This Toy transformer, in contrast, shows in miniature what happens when those ingredients aren’t present: even a well-designed architecture can only remix the fragments it has memorised.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaf258f-7fea-43df-b40e-57affe003885",
   "metadata": {},
   "source": [
    "# Unit tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024a4cab-c114-45c0-9169-c9da589085b9",
   "metadata": {},
   "source": [
    "## Scaled dot product attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fa6ee1b5-7b91-40da-83fe-0b15e599cef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_scaled_dot_product_attention_tiny_example():\n",
    "    \"\"\"\n",
    "    Sanity check for scaled_dot_product_attention on a tiny, hand-checkable example.\n",
    "\n",
    "    T = 3, d_k = d_v = 2.\n",
    "    \"\"\"\n",
    "    # ----- Define tiny Q, K, V (3 tokens, 2D vectors) -----\n",
    "    Q_base = torch.tensor([\n",
    "        [1.0, 0.0],\n",
    "        [0.0, 1.0],\n",
    "        [1.0, 1.0],\n",
    "    ])\n",
    "    K_base = torch.tensor([\n",
    "        [1.0, 0.0],\n",
    "        [1.0, 1.0],\n",
    "        [0.0, 1.0],\n",
    "    ])\n",
    "    V_base = torch.tensor([\n",
    "        [1.0, 2.0],\n",
    "        [0.0, 3.0],\n",
    "        [1.0, 0.0],\n",
    "    ])\n",
    "\n",
    "    # Shape to [B, H, T, d_k] / [B, H, T, d_v] with B=H=1\n",
    "    q = Q_base.unsqueeze(0).unsqueeze(0)  # [1, 1, 3, 2]\n",
    "    k = K_base.unsqueeze(0).unsqueeze(0)  # [1, 1, 3, 2]\n",
    "    v = V_base.unsqueeze(0).unsqueeze(0)  # [1, 1, 3, 2]\n",
    "\n",
    "    d_k = q.size(-1)\n",
    "\n",
    "    # ----- Manual step-by-step computation -----\n",
    "    # QK^T (unscaled scores): [1, 1, T, T]\n",
    "    scores_unscaled = q @ k.transpose(-2, -1)\n",
    "\n",
    "    # Scale by 1 / sqrt(d_k)\n",
    "    scores_scaled = scores_unscaled / math.sqrt(d_k)\n",
    "\n",
    "    # Row-wise softmax to get attention weights A\n",
    "    A = torch.softmax(scores_scaled, dim=-1)\n",
    "\n",
    "    # Multiply by V to get Y\n",
    "    Y_manual = A @ v  # [1, 1, T, d_v]\n",
    "\n",
    "    # ----- Use the actual implementation -----\n",
    "    Y_func = scaled_dot_product_attention(q, k, v, mask=None)\n",
    "\n",
    "\n",
    "    # ----- Check that implementation matches manual result -----\n",
    "    assert torch.allclose(Y_manual, Y_func, atol=1e-6), \"Mismatch between manual and function outputs!\"\n",
    "\n",
    "# Run the test once\n",
    "test_scaled_dot_product_attention_tiny_example()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fd6565-8c5b-4f79-9147-8f688620195e",
   "metadata": {},
   "source": [
    "## Self Attention with Causal Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "da58d9dc-bbc5-4b55-b4b1-fb404c32bb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_scaled_dot_product_attention_causal_mask_tiny_example():\n",
    "    \"\"\"\n",
    "    Sanity check for scaled_dot_product_attention with a causal mask.\n",
    "\n",
    "    Reuses a tiny T=3, d_k=d_v=2 example and applies a lower-triangular\n",
    "    causal mask so that position t cannot attend to positions > t.\n",
    "    \"\"\"\n",
    "\n",
    "    # ----- Same tiny Q, K, V as before -----\n",
    "    Q_base = torch.tensor([\n",
    "        [1.0, 0.0],\n",
    "        [0.0, 1.0],\n",
    "        [1.0, 1.0],\n",
    "    ])\n",
    "    K_base = torch.tensor([\n",
    "        [1.0, 0.0],\n",
    "        [1.0, 1.0],\n",
    "        [0.0, 1.0],\n",
    "    ])\n",
    "    V_base = torch.tensor([\n",
    "        [1.0, 2.0],\n",
    "        [0.0, 3.0],\n",
    "        [1.0, 0.0],\n",
    "    ])\n",
    "\n",
    "    # Shape to [B, H, T, d_k] / [B, H, T, d_v] with B=H=1\n",
    "    q = Q_base.unsqueeze(0).unsqueeze(0)  # [1, 1, 3, 2]\n",
    "    k = K_base.unsqueeze(0).unsqueeze(0)  # [1, 1, 3, 2]\n",
    "    v = V_base.unsqueeze(0).unsqueeze(0)  # [1, 1, 3, 2]\n",
    "\n",
    "    d_k = q.size(-1)\n",
    "    T = q.size(-2)\n",
    "\n",
    "    # ----- Unmasked scores for comparison -----\n",
    "    scores_unscaled = q @ k.transpose(-2, -1)            # [1, 1, T, T]\n",
    "    scores_scaled = scores_unscaled / math.sqrt(d_k)     # [1, 1, T, T]\n",
    "    A_unmasked = torch.softmax(scores_scaled, dim=-1)    # [1, 1, T, T]\n",
    "    Y_unmasked = A_unmasked @ v                          # [1, 1, T, d_v]\n",
    "\n",
    "    # ----- Construct causal mask (lower triangular) -----\n",
    "    # mask[t, t'] = 1 if t' <= t, 0 otherwise\n",
    "    causal_mask = torch.tril(torch.ones(T, T))           # [T, T]\n",
    "\n",
    "    # ----- Manual masked computation -----\n",
    "    scores_scaled_masked = scores_scaled.clone()  # [1, 1, T, T]\n",
    "    scores_scaled_masked[..., causal_mask == 0] = -float(\"inf\")\n",
    "    A_masked = torch.softmax(scores_scaled_masked, dim=-1)   # [1, 1, T, T]\n",
    "    Y_manual_masked = A_masked @ v                           # [1, 1, T, d_v]\n",
    "\n",
    "    # ----- Use the implementation with mask -----\n",
    "    Y_func_masked = scaled_dot_product_attention(\n",
    "        q, k, v, mask=causal_mask\n",
    "    )  # [1, 1, T, d_v]\n",
    "\n",
    "\n",
    "    # ----- Check that implementation matches manual result -----\n",
    "    assert torch.allclose(\n",
    "        Y_manual_masked, Y_func_masked, atol=1e-6\n",
    "    ), \"Masked attention output does not match manual computation!\"\n",
    "\n",
    "# Run the test once\n",
    "test_scaled_dot_product_attention_causal_mask_tiny_example()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6583cb61-2930-4701-ae49-1befb151f8ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
